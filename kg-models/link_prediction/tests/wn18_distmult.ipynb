{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from data import WN18\n",
    "from model.metrics import evaluate_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 21\n",
    "    n_epochs = 10\n",
    "    batch_size = 128\n",
    "    embed_dim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e: entity\n",
    "s: subject\n",
    "p: predicate\n",
    "o: object\n",
    "\"\"\"\n",
    "\n",
    "def read_triples(path):\n",
    "    triples = []\n",
    "    with open(path, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            s, p, o = line.split()\n",
    "            triples += [(s.strip(), p.strip(), o.strip())]\n",
    "    return triples\n",
    "\n",
    "\n",
    "def load_triple():\n",
    "    WN18.download()\n",
    "    triples_tr = read_triples('../data/WN18/wn18/train.txt')\n",
    "    triples_va = read_triples('../data/WN18/wn18/valid.txt')\n",
    "    triples_te = read_triples('../data/WN18/wn18/test.txt')\n",
    "    \n",
    "    triples_all = triples_tr + triples_va + triples_te\n",
    "    \n",
    "    return triples_all, triples_tr, triples_va, triples_te\n",
    "\n",
    "\n",
    "def build_vocab(triples):\n",
    "    params = {}\n",
    "    \n",
    "    e_set = {s for (s, p, o) in triples} | {o for (s, p, o) in triples}\n",
    "    p_set = {p for (s, p, o) in triples}\n",
    "\n",
    "    params['e_vocab_size'] = len(e_set)\n",
    "    params['p_vocab_size'] = len(p_set)\n",
    "\n",
    "    e2idx = {e: idx for idx, e in enumerate(sorted(e_set))}\n",
    "    p2idx = {p: idx for idx, p in enumerate(sorted(p_set))}\n",
    "    \n",
    "    return e2idx, p2idx, params\n",
    "\n",
    "\n",
    "def build_train_data(triples_tr, e2idx, p2idx):\n",
    "    x_s = np.array([e2idx[s] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_p = np.array([p2idx[p] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_o = np.array([e2idx[o] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "\n",
    "    x = {'s': x_s,\n",
    "         'p': x_p,\n",
    "         'o': x_o}\n",
    "    y = np.ones([len(x_s)], dtype=np.float32)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train_input_fn(triples_tr, e2idx, p2idx, random_state, params):\n",
    "    x, y = build_train_data(triples_tr, e2idx, p2idx)\n",
    "    s, p, o = x['s'], x['p'], x['o']\n",
    "    \n",
    "    s_ = random_state.choice(params['e_vocab_size'], s.shape)\n",
    "    o_ = random_state.choice(params['e_vocab_size'], o.shape)\n",
    "    \n",
    "    x_ = {\n",
    "        's': np.concatenate([s, s_, s]),\n",
    "        'p': np.concatenate([p, p, p]),\n",
    "        'o': np.concatenate([o, o, o_])}\n",
    "    y_ = np.concatenate([y, np.zeros([2*len(y)], dtype=np.float32)])\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(x = x_,\n",
    "                                              y = y_,\n",
    "                                              batch_size = Config.batch_size,\n",
    "                                              num_epochs = 1,\n",
    "                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features, params):\n",
    "    e_embed = tf.get_variable('e_embed',\n",
    "                              [params['e_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    p_embed = tf.get_variable('p_embed',\n",
    "                              [params['p_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    s = tf.nn.embedding_lookup(e_embed, features['s'])\n",
    "    p = tf.nn.embedding_lookup(p_embed, features['p'])\n",
    "    o = tf.nn.embedding_lookup(e_embed, features['o'])\n",
    "    \n",
    "    logits = tf.reduce_sum(s * p * o, [1])\n",
    "    \n",
    "    return logits\n",
    "    \n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    logits = forward(features, params)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info('\\n'+pprint.pformat(tf.trainable_variables()))\n",
    "        \n",
    "        loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                         labels=labels))\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer().minimize(\n",
    "            loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode,\n",
    "                                          loss = loss_op,\n",
    "                                          train_op = train_op)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions = tf.sigmoid(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Already Downloaded\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp9zpg0vhy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 10/10 [16:33<00:00, 99.31s/it]\n"
     ]
    }
   ],
   "source": [
    "random_state = np.random.RandomState(Config.seed)\n",
    "triples_all, triples_tr, triples_va, triples_te = load_triple()\n",
    "e2idx, p2idx, params = build_vocab(triples_all)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn,\n",
    "                               config = tf.estimator.RunConfig(\n",
    "                                   log_step_count_steps=len(triples_all)//Config.batch_size),\n",
    "                               params = params)\n",
    "\n",
    "for n_epoch in tqdm(range(Config.n_epochs), total=Config.n_epochs, ncols=70):\n",
    "    model.train(train_input_fn(triples_tr,\n",
    "                               e2idx,\n",
    "                               p2idx,\n",
    "                               random_state,\n",
    "                               params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [01:30<00:00, 55.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.5 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [01:30<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.7 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [03:40<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[valid] Raw Mean Rank: 864.7906\n",
      "[valid] Raw Hits@1: 41.48\n",
      "[valid] Raw Hits@3: 65.46\n",
      "[valid] Raw Hits@5: 73.67\n",
      "[valid] Raw Hits@10: 80.91000000000001\n",
      "[valid] Filtered Mean Rank: 853.1867\n",
      "[valid] Filtered Hits@1: 68.87\n",
      "[valid] Filtered Hits@3: 91.36999999999999\n",
      "[valid] Filtered Hits@5: 93.02\n",
      "[valid] Filtered Hits@10: 93.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [01:29<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.3 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [01:29<00:00, 55.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.9 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5000/5000 [03:37<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Raw Mean Rank: 782.583\n",
      "[test] Raw Hits@1: 40.88\n",
      "[test] Raw Hits@3: 65.12\n",
      "[test] Raw Hits@5: 73.74000000000001\n",
      "[test] Raw Hits@10: 81.31\n",
      "[test] Filtered Mean Rank: 770.9505\n",
      "[test] Filtered Hits@1: 69.07\n",
      "[test] Filtered Hits@3: 91.47999999999999\n",
      "[test] Filtered Hits@5: 93.02\n",
      "[test] Filtered Hits@10: 93.96\n"
     ]
    }
   ],
   "source": [
    "evaluate_rank(model,\n",
    "              triples_va,\n",
    "              triples_te,\n",
    "              triples_all,\n",
    "              e2idx,\n",
    "              p2idx,\n",
    "              params['e_vocab_size'],\n",
    "              batch_size = params['e_vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
