{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from data import WN18\n",
    "from model.metrics import evaluate_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 21\n",
    "    n_epochs = 10\n",
    "    batch_size = 128\n",
    "    embed_dim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e: entity\n",
    "s: subject\n",
    "p: predicate\n",
    "o: object\n",
    "\"\"\"\n",
    "\n",
    "def read_triples(path):\n",
    "    triples = []\n",
    "    with open(path, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            s, p, o = line.split()\n",
    "            triples += [(s.strip(), p.strip(), o.strip())]\n",
    "    return triples\n",
    "\n",
    "\n",
    "def load_triple():\n",
    "    WN18.download()\n",
    "    triples_tr = read_triples('../data/WN18/wn18/train.txt')\n",
    "    triples_va = read_triples('../data/WN18/wn18/valid.txt')\n",
    "    triples_te = read_triples('../data/WN18/wn18/test.txt')\n",
    "    \n",
    "    triples_all = triples_tr + triples_va + triples_te\n",
    "    \n",
    "    return triples_all, triples_tr, triples_va, triples_te\n",
    "\n",
    "\n",
    "def build_vocab(triples):\n",
    "    params = {}\n",
    "    \n",
    "    e_set = {s for (s, p, o) in triples} | {o for (s, p, o) in triples}\n",
    "    p_set = {p for (s, p, o) in triples}\n",
    "\n",
    "    params['e_vocab_size'] = len(e_set)\n",
    "    params['p_vocab_size'] = len(p_set)\n",
    "\n",
    "    e2idx = {e: idx for idx, e in enumerate(sorted(e_set))}\n",
    "    p2idx = {p: idx for idx, p in enumerate(sorted(p_set))}\n",
    "    \n",
    "    return e2idx, p2idx, params\n",
    "\n",
    "\n",
    "def build_train_data(triples_tr, e2idx, p2idx):\n",
    "    x_s = np.array([e2idx[s] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_p = np.array([p2idx[p] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_o = np.array([e2idx[o] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "\n",
    "    x = {'s': x_s,\n",
    "         'p': x_p,\n",
    "         'o': x_o}\n",
    "    y = np.ones([len(x_s)], dtype=np.float32)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train_input_fn(triples_tr, e2idx, p2idx, random_state, params):\n",
    "    x, y = build_train_data(triples_tr, e2idx, p2idx)\n",
    "    s, p, o = x['s'], x['p'], x['o']\n",
    "    \n",
    "    s_ = random_state.choice(params['e_vocab_size'], s.shape)\n",
    "    o_ = random_state.choice(params['e_vocab_size'], o.shape)\n",
    "    \n",
    "    x_ = {\n",
    "        's': np.concatenate([s, s_, s]),\n",
    "        'p': np.concatenate([p, p, p]),\n",
    "        'o': np.concatenate([o, o, o_])}\n",
    "    y_ = np.concatenate([y, np.zeros([2*len(y)], dtype=np.float32)])\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(x = x_,\n",
    "                                              y = y_,\n",
    "                                              batch_size = Config.batch_size,\n",
    "                                              num_epochs = 1,\n",
    "                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features, params):\n",
    "    e_embed = tf.get_variable('e_embed',\n",
    "                              [params['e_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    p_embed = tf.get_variable('p_embed',\n",
    "                              [params['p_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    s = tf.nn.embedding_lookup(e_embed, features['s'])\n",
    "    p = tf.nn.embedding_lookup(p_embed, features['p'])\n",
    "    o = tf.nn.embedding_lookup(e_embed, features['o'])\n",
    "    \n",
    "    logits = tf.reduce_sum(s * p * o, [1])\n",
    "    \n",
    "    return logits\n",
    "    \n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    logits = forward(features, params)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info('\\n'+pprint.pformat(tf.trainable_variables()))\n",
    "        \n",
    "        loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                         labels=labels))\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer().minimize(\n",
    "            loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode,\n",
    "                                          loss = loss_op,\n",
    "                                          train_op = train_op)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions = tf.sigmoid(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmp96m4z4zw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 10/10 [18:06<00:00, 108.69s/it]\n"
     ]
    }
   ],
   "source": [
    "random_state = np.random.RandomState(Config.seed)\n",
    "triples_all, triples_tr, triples_va, triples_te = load_triple()\n",
    "e2idx, p2idx, params = build_vocab(triples_all)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn,\n",
    "                               params = params)\n",
    "\n",
    "for n_epoch in tqdm(range(Config.n_epochs), total=Config.n_epochs, ncols=70):\n",
    "    model.train(train_input_fn(triples_tr,\n",
    "                               e2idx,\n",
    "                               p2idx,\n",
    "                               random_state,\n",
    "                               params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████▉| 4996/5000 [02:17<00:00, 36.24it/s]\n",
      "  0%|                                        | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                | 4/5000 [00:00<02:13, 37.51it/s]\u001b[A\n",
      "  0%|                                | 8/5000 [00:00<02:11, 37.98it/s]\u001b[A\n",
      "  0%|                               | 12/5000 [00:00<02:11, 38.07it/s]\u001b[A\n",
      "  0%|                               | 16/5000 [00:00<02:10, 38.16it/s]\u001b[A\n",
      "  0%|                               | 20/5000 [00:00<02:10, 38.09it/s]\u001b[A\n",
      "  0%|▏                              | 24/5000 [00:00<02:11, 37.83it/s]\u001b[A\n",
      "  1%|▏                              | 28/5000 [00:00<02:11, 37.78it/s]\u001b[A\n",
      "  1%|▏                              | 32/5000 [00:00<02:11, 37.90it/s]\u001b[A\n",
      "  1%|▏                              | 36/5000 [00:00<02:10, 37.94it/s]\u001b[A\n",
      "  1%|▏                              | 40/5000 [00:01<02:10, 37.97it/s]\u001b[A\n",
      "  1%|▎                              | 44/5000 [00:01<02:10, 37.90it/s]\u001b[A\n",
      "  1%|▎                              | 48/5000 [00:01<02:11, 37.63it/s]\u001b[A\n",
      "  1%|▎                              | 52/5000 [00:01<02:12, 37.29it/s]\u001b[A\n",
      "  1%|▎                              | 56/5000 [00:01<02:12, 37.37it/s]\u001b[A\n",
      "  1%|▎                              | 60/5000 [00:01<02:11, 37.49it/s]\u001b[A\n",
      "  1%|▍                              | 64/5000 [00:01<02:11, 37.52it/s]\u001b[A\n",
      "100%|████████████████████████████▉| 4996/5000 [02:18<00:00, 36.13it/s]\n",
      "  0%|                                        | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                | 2/5000 [00:00<04:15, 19.53it/s]\u001b[A\n",
      "  0%|                                | 4/5000 [00:00<04:15, 19.59it/s]\u001b[A\n",
      "  0%|                                | 7/5000 [00:00<04:10, 19.90it/s]\u001b[A\n",
      "  0%|                                | 9/5000 [00:00<04:11, 19.86it/s]\u001b[A\n",
      "  0%|                               | 11/5000 [00:00<04:11, 19.87it/s]\u001b[A\n",
      "  0%|                               | 13/5000 [00:00<04:11, 19.85it/s]\u001b[A\n",
      "  0%|                               | 15/5000 [00:00<04:13, 19.68it/s]\u001b[A\n",
      "  0%|                               | 17/5000 [00:00<04:13, 19.63it/s]\u001b[A\n",
      "  0%|                               | 19/5000 [00:00<04:14, 19.57it/s]\u001b[A\n",
      "  0%|▏                              | 22/5000 [00:01<04:12, 19.68it/s]\u001b[A\n",
      "  0%|▏                              | 25/5000 [00:01<04:11, 19.81it/s]\u001b[A\n",
      "  1%|▏                              | 27/5000 [00:01<04:11, 19.78it/s]\u001b[A\n",
      "  1%|▏                              | 29/5000 [00:01<04:12, 19.72it/s]\u001b[A\n",
      "  1%|▏                              | 31/5000 [00:01<04:12, 19.70it/s]\u001b[A\n",
      "  1%|▏                              | 33/5000 [00:01<04:12, 19.68it/s]\u001b[A\n",
      "  1%|▏                              | 36/5000 [00:01<04:11, 19.74it/s]\u001b[A\n",
      "  1%|▏                              | 38/5000 [00:01<04:12, 19.67it/s]\u001b[A\n",
      "  1%|▏                              | 40/5000 [00:02<04:12, 19.63it/s]\u001b[A\n",
      "  1%|▎                              | 42/5000 [00:02<04:12, 19.61it/s]\u001b[A\n",
      "  1%|▎                              | 44/5000 [00:02<04:13, 19.55it/s]\u001b[A\n",
      "  1%|▎                              | 47/5000 [00:02<04:12, 19.63it/s]\u001b[A\n",
      "  1%|▎                              | 49/5000 [00:02<04:12, 19.63it/s]\u001b[A\n",
      "  1%|▎                              | 51/5000 [00:02<04:12, 19.61it/s]\u001b[A\n",
      "  1%|▎                              | 53/5000 [00:02<04:12, 19.61it/s]\u001b[A\n",
      "  1%|▎                              | 55/5000 [00:02<04:12, 19.59it/s]\u001b[A\n",
      "  1%|▎                              | 57/5000 [00:02<04:12, 19.59it/s]\u001b[A\n",
      "  1%|▎                              | 59/5000 [00:03<04:12, 19.57it/s]\u001b[A\n",
      "  1%|▍                              | 62/5000 [00:03<04:12, 19.58it/s]\u001b[A\n",
      "  1%|▍                              | 64/5000 [00:03<04:12, 19.58it/s]\u001b[A\n",
      "  1%|▍                              | 66/5000 [00:03<04:11, 19.58it/s]\u001b[A\n",
      "100%|█████████████████████████████| 5000/5000 [04:07<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[valid] Raw Mean Rank: 888.1724\n",
      "[valid] Raw Hits@1: 40.489999999999995\n",
      "[valid] Raw Hits@3: 64.69\n",
      "[valid] Raw Hits@5: 73.47\n",
      "[valid] Raw Hits@10: 80.86\n",
      "[valid] Filtered Mean Rank: 876.3531\n",
      "[valid] Filtered Hits@1: 64.16\n",
      "[valid] Filtered Hits@3: 89.38000000000001\n",
      "[valid] Filtered Hits@5: 92.05\n",
      "[valid] Filtered Hits@10: 93.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████▉| 4998/5000 [02:17<00:00, 36.27it/s]\n",
      "  0%|                                        | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                | 4/5000 [00:00<02:32, 32.81it/s]\u001b[A\n",
      "  0%|                                | 8/5000 [00:00<02:31, 33.04it/s]\u001b[A\n",
      "  0%|                               | 12/5000 [00:00<02:25, 34.19it/s]\u001b[A\n",
      "  0%|                               | 16/5000 [00:00<02:25, 34.32it/s]\u001b[A\n",
      "  0%|                               | 20/5000 [00:00<02:23, 34.62it/s]\u001b[A\n",
      "  0%|▏                              | 24/5000 [00:00<02:22, 34.95it/s]\u001b[A\n",
      "  1%|▏                              | 28/5000 [00:00<02:22, 34.96it/s]\u001b[A\n",
      "  1%|▏                              | 32/5000 [00:00<02:21, 34.99it/s]\u001b[A\n",
      "  1%|▏                              | 36/5000 [00:01<02:21, 35.02it/s]\u001b[A\n",
      "  1%|▏                              | 40/5000 [00:01<02:21, 35.10it/s]\u001b[A\n",
      "  1%|▎                              | 44/5000 [00:01<02:21, 35.10it/s]\u001b[A\n",
      "  1%|▎                              | 48/5000 [00:01<02:21, 34.97it/s]\u001b[A\n",
      "  1%|▎                              | 52/5000 [00:01<02:22, 34.76it/s]\u001b[A\n",
      "  1%|▎                              | 56/5000 [00:01<02:22, 34.70it/s]\u001b[A\n",
      "  1%|▎                              | 60/5000 [00:01<02:23, 34.39it/s]\u001b[A\n",
      "100%|████████████████████████████▉| 4997/5000 [02:19<00:00, 35.77it/s]\n",
      "  0%|                                        | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|                                | 1/5000 [00:00<18:02,  4.62it/s]\u001b[A\n",
      "  0%|                                | 3/5000 [00:00<09:00,  9.24it/s]\u001b[A\n",
      "  0%|                                | 6/5000 [00:00<06:30, 12.78it/s]\u001b[A\n",
      "  0%|                                | 8/5000 [00:00<05:57, 13.98it/s]\u001b[A\n",
      "  0%|                               | 10/5000 [00:00<05:36, 14.83it/s]\u001b[A\n",
      "  0%|                               | 12/5000 [00:00<05:23, 15.42it/s]\u001b[A\n",
      "  0%|                               | 14/5000 [00:00<05:13, 15.88it/s]\u001b[A\n",
      "  0%|                               | 16/5000 [00:00<05:05, 16.29it/s]\u001b[A\n",
      "  0%|                               | 18/5000 [00:01<05:00, 16.57it/s]\u001b[A\n",
      "  0%|                               | 20/5000 [00:01<04:55, 16.85it/s]\u001b[A\n",
      "  0%|▏                              | 22/5000 [00:01<04:51, 17.08it/s]\u001b[A\n",
      "  0%|▏                              | 25/5000 [00:01<04:45, 17.42it/s]\u001b[A\n",
      "  1%|▏                              | 27/5000 [00:01<04:43, 17.57it/s]\u001b[A\n",
      "  1%|▏                              | 29/5000 [00:01<04:40, 17.71it/s]\u001b[A\n",
      "  1%|▏                              | 31/5000 [00:01<04:39, 17.77it/s]\u001b[A\n",
      "  1%|▏                              | 33/5000 [00:01<04:37, 17.87it/s]\u001b[A\n",
      "  1%|▏                              | 36/5000 [00:01<04:35, 18.04it/s]\u001b[A\n",
      "100%|█████████████████████████████| 5000/5000 [04:05<00:00, 20.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] Raw Mean Rank: 805.2557\n",
      "[test] Raw Hits@1: 39.989999999999995\n",
      "[test] Raw Hits@3: 64.66\n",
      "[test] Raw Hits@5: 73.54\n",
      "[test] Raw Hits@10: 81.38\n",
      "[test] Filtered Mean Rank: 793.711\n",
      "[test] Filtered Hits@1: 63.849999999999994\n",
      "[test] Filtered Hits@3: 90.18\n",
      "[test] Filtered Hits@5: 92.46\n",
      "[test] Filtered Hits@10: 93.93\n"
     ]
    }
   ],
   "source": [
    "evaluate_rank(model,\n",
    "              triples_va,\n",
    "              triples_te,\n",
    "              triples_all,\n",
    "              e2idx,\n",
    "              p2idx,\n",
    "              params['e_vocab_size'],\n",
    "              batch_size = Config.batch_size*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
