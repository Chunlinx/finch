{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pprint\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from data import WN18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 21\n",
    "    n_epochs = 10\n",
    "    batch_size = 128\n",
    "    embed_dim = 150\n",
    "    margin = 5\n",
    "    lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e: entity\n",
    "s: subject\n",
    "p: predicate\n",
    "o: object\n",
    "\"\"\"\n",
    "\n",
    "def read_triples(path):\n",
    "    triples = []\n",
    "    with open(path, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            s, p, o = line.split()\n",
    "            triples += [(s.strip(), p.strip(), o.strip())]\n",
    "    return triples\n",
    "\n",
    "\n",
    "def load_triple():\n",
    "    WN18.download()\n",
    "    triples_tr = read_triples('../data/WN18/wn18/train.txt')\n",
    "    triples_va = read_triples('../data/WN18/wn18/valid.txt')\n",
    "    triples_te = read_triples('../data/WN18/wn18/test.txt')\n",
    "    \n",
    "    triples_all = triples_tr + triples_va + triples_te\n",
    "    \n",
    "    return triples_all, triples_tr, triples_va, triples_te\n",
    "\n",
    "\n",
    "def build_vocab(triples):\n",
    "    params = {}\n",
    "    \n",
    "    e_set = {s for (s, p, o) in triples} | {o for (s, p, o) in triples}\n",
    "    p_set = {p for (s, p, o) in triples}\n",
    "\n",
    "    params['e_vocab_size'] = len(e_set)\n",
    "    params['p_vocab_size'] = len(p_set)\n",
    "\n",
    "    e2idx = {e: idx for idx, e in enumerate(sorted(e_set))}\n",
    "    p2idx = {p: idx for idx, p in enumerate(sorted(p_set))}\n",
    "    \n",
    "    return e2idx, p2idx, params\n",
    "\n",
    "\n",
    "def build_train_data(triples_tr, e2idx, p2idx):\n",
    "    x_s = np.array([e2idx[s] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_p = np.array([p2idx[p] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "    x_o = np.array([e2idx[o] for (s, p, o) in triples_tr], dtype=np.int32)\n",
    "\n",
    "    x = {'s': x_s,\n",
    "         'p': x_p,\n",
    "         'o': x_o}\n",
    "    y = np.ones([len(x_s)], dtype=np.float32)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train_input_fn(triples_tr, e2idx, p2idx, random_state, params):\n",
    "    x, y = build_train_data(triples_tr, e2idx, p2idx)\n",
    "    s, p, o = x['s'], x['p'], x['o']\n",
    "    \n",
    "    s_ = random_state.permutation(s)\n",
    "    o_ = random_state.permutation(o)\n",
    "    \n",
    "    x_ = {\n",
    "        's': np.concatenate([s, s_, s]),\n",
    "        'p': np.concatenate([p, p, p]),\n",
    "        'o': np.concatenate([o, o, o_]),\n",
    "    }\n",
    "    y_ = np.concatenate([y, np.zeros([2*len(y)], dtype=np.float32)])\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(x = x_,\n",
    "                                              y = y_,\n",
    "                                              batch_size = Config.batch_size,\n",
    "                                              num_epochs = Config.n_epochs,\n",
    "                                              shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features, params):\n",
    "    e_embed = tf.get_variable('e_embed',\n",
    "                              [params['e_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    p_embed = tf.get_variable('p_embed',\n",
    "                              [params['p_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    s = tf.nn.embedding_lookup(e_embed, features['s'])\n",
    "    p = tf.nn.embedding_lookup(p_embed, features['p'])\n",
    "    o = tf.nn.embedding_lookup(e_embed, features['o'])\n",
    "    \n",
    "    scores = tf.reduce_sum(s * p * o, axis=1)\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    scores = forward(features, params)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        hinge_loss = tf.nn.relu(Config.margin - scores * (2 * labels - 1))\n",
    "        loss_op = tf.reduce_sum(hinge_loss)\n",
    "        train_op = tf.train.AdagradOptimizer(Config.lr).minimize(\n",
    "            loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode,\n",
    "                                          loss = tf.reduce_mean(hinge_loss),\n",
    "                                          train_op = train_op)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Already Downloaded\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmprrqfnxso\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmprrqfnxso', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1105, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11a190da0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmprrqfnxso/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.000004, step = 1\n",
      "INFO:tensorflow:global_step/sec: 499.119\n",
      "INFO:tensorflow:loss = 4.9999948, step = 1106 (2.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.946\n",
      "INFO:tensorflow:loss = 4.9999933, step = 2211 (2.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.998\n",
      "INFO:tensorflow:loss = 4.9999437, step = 3316 (2.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.783\n",
      "INFO:tensorflow:loss = 4.9972878, step = 4421 (2.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.321\n",
      "INFO:tensorflow:loss = 4.4598913, step = 5526 (2.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.129\n",
      "INFO:tensorflow:loss = 7.473745, step = 6631 (2.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.827\n",
      "INFO:tensorflow:loss = 4.1282024, step = 7736 (2.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.479\n",
      "INFO:tensorflow:loss = 2.7990272, step = 8841 (2.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.093\n",
      "INFO:tensorflow:loss = 6.302005, step = 9946 (2.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.422\n",
      "INFO:tensorflow:loss = 1.5995369, step = 11051 (2.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.382\n",
      "INFO:tensorflow:loss = 1.1039685, step = 12156 (2.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.231\n",
      "INFO:tensorflow:loss = 1.5098131, step = 13261 (2.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.143\n",
      "INFO:tensorflow:loss = 0.2762816, step = 14366 (1.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.519\n",
      "INFO:tensorflow:loss = 0.31389254, step = 15471 (2.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.229\n",
      "INFO:tensorflow:loss = 0.18539928, step = 16576 (1.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.051\n",
      "INFO:tensorflow:loss = 0.056949984, step = 17681 (1.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.16\n",
      "INFO:tensorflow:loss = 0.14618446, step = 18786 (1.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.977\n",
      "INFO:tensorflow:loss = 0.0014307015, step = 19891 (2.039 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.958\n",
      "INFO:tensorflow:loss = 0.0, step = 20996 (2.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.04\n",
      "INFO:tensorflow:loss = 0.0, step = 22101 (2.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.407\n",
      "INFO:tensorflow:loss = 0.0, step = 23206 (2.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.848\n",
      "INFO:tensorflow:loss = 0.0, step = 24311 (2.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.664\n",
      "INFO:tensorflow:loss = 0.0, step = 25416 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.424\n",
      "INFO:tensorflow:loss = 0.008609274, step = 26521 (2.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.5\n",
      "INFO:tensorflow:loss = 0.0, step = 27626 (2.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.095\n",
      "INFO:tensorflow:loss = 0.085528806, step = 28731 (2.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.288\n",
      "INFO:tensorflow:loss = 0.0051667355, step = 29836 (2.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.455\n",
      "INFO:tensorflow:loss = 0.0, step = 30941 (2.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.773\n",
      "INFO:tensorflow:loss = 0.0, step = 32046 (1.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.392\n",
      "INFO:tensorflow:loss = 0.0, step = 33151 (2.056 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33151 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmprrqfnxso/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x11a190be0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = np.random.RandomState(Config.seed)\n",
    "triples_all, triples_tr, triples_va, triples_te = load_triple()\n",
    "e2idx, p2idx, params = build_vocab(triples_all)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn,\n",
    "                               config = tf.estimator.RunConfig(\n",
    "                                   log_step_count_steps=len(triples_tr)//Config.batch_size),\n",
    "                               params = params)\n",
    "\n",
    "model.train(train_input_fn(triples_tr, e2idx, p2idx, random_state, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
