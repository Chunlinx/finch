{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pprint\n",
    "import itertools\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from data import WN18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 21\n",
    "    n_epochs = 10\n",
    "    batch_size = 128\n",
    "    embed_dim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "e: entity\n",
    "s: subject\n",
    "p: predicate\n",
    "o: object\n",
    "\"\"\"\n",
    "\n",
    "def read_triples(path):\n",
    "    triples = []\n",
    "    with open(path, 'rt') as f:\n",
    "        for line in f.readlines():\n",
    "            s, p, o = line.split()\n",
    "            triples += [(s.strip(), p.strip(), o.strip())]\n",
    "    return triples\n",
    "\n",
    "\n",
    "def load_triple():\n",
    "    WN18.download()\n",
    "    triples_tr = read_triples('../data/WN18/wn18/train.txt')\n",
    "    triples_va = read_triples('../data/WN18/wn18/valid.txt')\n",
    "    triples_te = read_triples('../data/WN18/wn18/test.txt')\n",
    "    \n",
    "    triples_all = triples_tr + triples_va + triples_te\n",
    "    \n",
    "    return triples_all, triples_tr, triples_va, triples_te\n",
    "\n",
    "\n",
    "def build_vocab(triples):\n",
    "    params = {}\n",
    "    \n",
    "    e_set = {s for (s, p, o) in triples} | {o for (s, p, o) in triples}\n",
    "    p_set = {p for (s, p, o) in triples}\n",
    "\n",
    "    params['e_vocab_size'] = len(e_set)\n",
    "    params['p_vocab_size'] = len(p_set)\n",
    "\n",
    "    e2idx = {e: idx for idx, e in enumerate(sorted(e_set))}\n",
    "    p2idx = {p: idx for idx, p in enumerate(sorted(p_set))}\n",
    "    \n",
    "    return e2idx, p2idx, params\n",
    "\n",
    "\n",
    "def build_multi_label(triples_tr):\n",
    "    s2p2o = {}\n",
    "    for (_s, _p, _o) in triples_tr:\n",
    "        s, p, o = e2idx[_s], p2idx[_p], e2idx[_o] \n",
    "        if s not in s2p2o:\n",
    "            s2p2o[s] = {p: [o]}\n",
    "        if p not in s2p2o[s]:\n",
    "            s2p2o[s][p] = [o]\n",
    "        if o not in s2p2o[s][p]:\n",
    "            s2p2o[s][p].append(o)\n",
    "    return s2p2o\n",
    "\n",
    "\n",
    "def next_train_batch(triples_tr, e2idx, p2idx, s2p2o):\n",
    "    triples_tr = sklearn.utils.shuffle(triples_tr)\n",
    "    for i in range(0, len(triples_tr), Config.batch_size):\n",
    "        _triples_tr = triples_tr[i : i+Config.batch_size]\n",
    "        x_s = np.asarray([e2idx[s] for (s, p, o) in _triples_tr], dtype=np.int32)\n",
    "        x_p = np.asarray([p2idx[p] for (s, p, o) in _triples_tr], dtype=np.int32)\n",
    "        y = []\n",
    "        for (_s, _p, _o) in _triples_tr:\n",
    "            s, p, o = e2idx[_s], p2idx[_p], e2idx[_o] \n",
    "            temp = np.zeros([len(e2idx)])\n",
    "            temp[s2p2o[s][p]] = 1.\n",
    "            y.append(temp)\n",
    "        y = np.asarray(y)\n",
    "        yield x_s, x_p, y\n",
    "\n",
    "\n",
    "def train_input_fn(triples_tr, e2idx, p2idx, s2p2o):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: next_train_batch(triples_tr, e2idx, p2idx, s2p2o),\n",
    "        (tf.int32, tf.int32, tf.float32),\n",
    "        (tf.TensorShape([None]),\n",
    "         tf.TensorShape([None]),\n",
    "         tf.TensorShape([None, len(e2idx)])))\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    x_s, x_p, y = iterator.get_next()\n",
    "    return {'s': x_s, 'p': x_p}, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features, params):\n",
    "    e_embed = tf.get_variable('e_embed',\n",
    "                              [params['e_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    p_embed = tf.get_variable('p_embed',\n",
    "                              [params['p_vocab_size'], Config.embed_dim],\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    s = tf.nn.embedding_lookup(e_embed, features['s'])\n",
    "    p = tf.nn.embedding_lookup(p_embed, features['p'])\n",
    "    \n",
    "    logits = tf.matmul((s * p), e_embed, transpose_b=True)\n",
    "    \n",
    "    return logits\n",
    "    \n",
    "    \n",
    "def model_fn(features, labels, mode, params):\n",
    "    logits = forward(features, params)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info('\\n'+pprint.pformat(tf.trainable_variables()))\n",
    "        \n",
    "        loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                                         labels=labels))\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer().minimize(\n",
    "            loss_op, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode,\n",
    "                                          loss = loss_op,\n",
    "                                          train_op = train_op)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions = tf.sigmoid(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Already Downloaded\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeyu2y6ui\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeyu2y6ui', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11ebde048>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:\n",
      "[<tf.Variable 'e_embed:0' shape=(40943, 150) dtype=float32_ref>,\n",
      " <tf.Variable 'p_embed:0' shape=(18, 150) dtype=float32_ref>]\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeyu2y6ui/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.68932664, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.90037\n",
      "INFO:tensorflow:loss = 0.68932444, step = 101 (34.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.91589\n",
      "INFO:tensorflow:loss = 0.6176116, step = 201 (34.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.04706\n",
      "INFO:tensorflow:loss = 0.17413755, step = 301 (32.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.01949\n",
      "INFO:tensorflow:loss = 0.07582444, step = 401 (33.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12713\n",
      "INFO:tensorflow:loss = 0.04750728, step = 501 (31.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10179\n",
      "INFO:tensorflow:loss = 0.02456294, step = 601 (32.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06105\n",
      "INFO:tensorflow:loss = 0.017964711, step = 701 (32.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.82505\n",
      "INFO:tensorflow:loss = 0.012253888, step = 801 (35.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.23557\n",
      "INFO:tensorflow:loss = 0.009072402, step = 901 (30.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.00082\n",
      "INFO:tensorflow:loss = 0.008398667, step = 1001 (33.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.85417\n",
      "INFO:tensorflow:loss = 0.006845207, step = 1101 (35.037 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1106 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpeyu2y6ui/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0022325686.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x11ebde588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_all, triples_tr, triples_va, triples_te = load_triple()\n",
    "e2idx, p2idx, params = build_vocab(triples_all)\n",
    "s2p2o = build_multi_label(triples_tr)\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn, params = params)\n",
    "\n",
    "#for n_epoch in tqdm(range(Config.n_epochs), total=Config.n_epochs, ncols=70):\n",
    "model.train(lambda: train_input_fn(triples_tr, e2idx, p2idx, s2p2o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
